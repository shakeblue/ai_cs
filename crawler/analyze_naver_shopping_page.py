#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ë„¤ì´ë²„ ì‡¼í•‘ ì „ì‹œ í˜ì´ì§€ êµ¬ì¡° ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
í˜ì´ì§€ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ í¬ë¡¤ëŸ¬ ê°œë°œì— í•„ìš”í•œ CSS ì„ íƒìë¥¼ ì°¾ìŠµë‹ˆë‹¤.
"""

import time
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import re

def analyze_page():
    """ë„¤ì´ë²„ ì‡¼í•‘ ì „ì‹œ í˜ì´ì§€ ë¶„ì„"""
    
    # ìƒ˜í”Œ URL
    _v_url = "https://brand.naver.com/iope/shoppingstory/detail?id=5002337684"
    
    print("=" * 80)
    print("ë„¤ì´ë²„ ì‡¼í•‘ ì „ì‹œ í˜ì´ì§€ êµ¬ì¡° ë¶„ì„")
    print("=" * 80)
    print(f"\në¶„ì„ URL: {_v_url}\n")
    
    # Chrome ì˜µì…˜ ì„¤ì •
    _v_chrome_options = Options()
    _v_chrome_options.add_argument('--headless')  # í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ
    _v_chrome_options.add_argument('--no-sandbox')
    _v_chrome_options.add_argument('--disable-dev-shm-usage')
    _v_chrome_options.add_argument('--disable-gpu')
    _v_chrome_options.add_argument('--window-size=1920,1080')
    _v_chrome_options.add_argument('--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36')
    
    # WebDriver ì´ˆê¸°í™”
    _v_driver = webdriver.Chrome(
        service=Service(ChromeDriverManager().install()),
        options=_v_chrome_options
    )
    
    try:
        # í˜ì´ì§€ ë¡œë“œ
        print("ğŸ“„ í˜ì´ì§€ ë¡œë”© ì¤‘...")
        _v_driver.get(_v_url)
        time.sleep(5)  # ë™ì  ì½˜í…ì¸  ë¡œë”© ëŒ€ê¸°
        
        # í˜ì´ì§€ ìŠ¤í¬ë¡¤ (lazy loading ì½˜í…ì¸  ë¡œë“œ)
        print("ğŸ“œ í˜ì´ì§€ ìŠ¤í¬ë¡¤ ì¤‘...")
        _v_driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(3)
        _v_driver.execute_script("window.scrollTo(0, 0);")
        time.sleep(2)
        
        # HTML ì €ì¥
        _v_html = _v_driver.page_source
        with open('naver_shopping_page_source.html', 'w', encoding='utf-8') as f:
            f.write(_v_html)
        print("âœ… HTML ì†ŒìŠ¤ ì €ì¥: naver_shopping_page_source.html")
        
        # ìŠ¤í¬ë¦°ìƒ· ì €ì¥
        _v_driver.save_screenshot('naver_shopping_screenshot.png')
        print("âœ… ìŠ¤í¬ë¦°ìƒ· ì €ì¥: naver_shopping_screenshot.png")
        
        # BeautifulSoupìœ¼ë¡œ íŒŒì‹±
        _v_soup = BeautifulSoup(_v_html, 'html.parser')
        
        print("\n" + "=" * 80)
        print("ğŸ“Š í˜ì´ì§€ êµ¬ì¡° ë¶„ì„ ê²°ê³¼")
        print("=" * 80)
        
        # 1. íƒ€ì´í‹€ ì°¾ê¸°
        print("\n[1] í–‰ì‚¬ íƒ€ì´í‹€ í›„ë³´:")
        _v_title_selectors = [
            'h1', 'h2', 'h3',
            '[class*="title"]', '[class*="Title"]',
            '[class*="heading"]', '[class*="Heading"]',
            '[class*="name"]', '[class*="Name"]'
        ]
        for selector in _v_title_selectors:
            elements = _v_soup.select(selector)
            if elements:
                for idx, elem in enumerate(elements[:3], 1):
                    text = elem.get_text(strip=True)
                    if text and len(text) > 3:
                        print(f"   {selector} [{idx}]: {text[:100]}")
        
        # 2. ë‚ ì§œ ì •ë³´ ì°¾ê¸°
        print("\n[2] í–‰ì‚¬ ì¼ì í›„ë³´:")
        _v_date_pattern = re.compile(r'\d{2,4}[./-]\d{1,2}[./-]\d{1,2}')
        _v_all_text = _v_soup.get_text()
        _v_dates = _v_date_pattern.findall(_v_all_text)
        if _v_dates:
            print(f"   ë°œê²¬ëœ ë‚ ì§œ íŒ¨í„´: {set(_v_dates)}")
        
        # ë‚ ì§œ ê´€ë ¨ í´ë˜ìŠ¤ ì°¾ê¸°
        _v_date_selectors = [
            '[class*="date"]', '[class*="Date"]',
            '[class*="period"]', '[class*="Period"]',
            '[class*="time"]', '[class*="Time"]'
        ]
        for selector in _v_date_selectors:
            elements = _v_soup.select(selector)
            if elements:
                for idx, elem in enumerate(elements[:3], 1):
                    text = elem.get_text(strip=True)
                    if text:
                        print(f"   {selector} [{idx}]: {text[:100]}")
        
        # 3. í˜œíƒ ì •ë³´ ì°¾ê¸°
        print("\n[3] í˜œíƒ ì •ë³´ í›„ë³´:")
        _v_benefit_selectors = [
            '[class*="benefit"]', '[class*="Benefit"]',
            '[class*="coupon"]', '[class*="Coupon"]',
            '[class*="event"]', '[class*="Event"]',
            '[class*="promotion"]', '[class*="Promotion"]',
            '[class*="gift"]', '[class*="Gift"]'
        ]
        for selector in _v_benefit_selectors:
            elements = _v_soup.select(selector)
            if elements:
                print(f"   {selector}: {len(elements)}ê°œ ë°œê²¬")
                for idx, elem in enumerate(elements[:2], 1):
                    text = elem.get_text(strip=True)
                    if text and len(text) > 5:
                        print(f"      [{idx}]: {text[:150]}")
        
        # 4. ì¿ í° ì •ë³´ ì°¾ê¸°
        print("\n[4] ì¿ í° ì •ë³´ í›„ë³´:")
        _v_coupon_keywords = ['ì¿ í°', 'COUPON', 'coupon']
        for keyword in _v_coupon_keywords:
            elements = _v_soup.find_all(string=re.compile(keyword))
            if elements:
                print(f"   '{keyword}' í‚¤ì›Œë“œ: {len(elements)}ê°œ ë°œê²¬")
                for idx, elem in enumerate(elements[:3], 1):
                    parent_class = elem.parent.get('class', [])
                    print(f"      [{idx}]: {elem.strip()[:100]}")
                    print(f"           ë¶€ëª¨ í´ë˜ìŠ¤: {parent_class}")
        
        # 5. ê¸ˆì•¡ëŒ€ë³„ í˜œíƒ ì°¾ê¸°
        print("\n[5] ê¸ˆì•¡ëŒ€ë³„ í˜œíƒ í›„ë³´:")
        _v_price_pattern = re.compile(r'\d+ë§Œ?\s*ì›')
        _v_price_texts = _v_soup.find_all(string=_v_price_pattern)
        if _v_price_texts:
            print(f"   ê¸ˆì•¡ íŒ¨í„´: {len(_v_price_texts)}ê°œ ë°œê²¬")
            for idx, text in enumerate(_v_price_texts[:5], 1):
                parent_class = text.parent.get('class', [])
                print(f"      [{idx}]: {text.strip()[:100]}")
                print(f"           ë¶€ëª¨ í´ë˜ìŠ¤: {parent_class}")
        
        # 6. ìƒí’ˆ ì •ë³´ ì°¾ê¸°
        print("\n[6] ìƒí’ˆ ì •ë³´ í›„ë³´:")
        _v_product_selectors = [
            '[class*="product"]', '[class*="Product"]',
            '[class*="item"]', '[class*="Item"]',
            '[class*="goods"]', '[class*="Goods"]'
        ]
        for selector in _v_product_selectors:
            elements = _v_soup.select(selector)
            if elements:
                print(f"   {selector}: {len(elements)}ê°œ ë°œê²¬")
                for idx, elem in enumerate(elements[:2], 1):
                    # ìƒí’ˆëª… ì°¾ê¸°
                    name_elem = elem.select_one('[class*="name"], [class*="Name"], [class*="title"], [class*="Title"]')
                    if name_elem:
                        print(f"      [{idx}] ìƒí’ˆëª…: {name_elem.get_text(strip=True)[:100]}")
                    
                    # ê°€ê²© ì°¾ê¸°
                    price_elem = elem.select_one('[class*="price"], [class*="Price"]')
                    if price_elem:
                        print(f"           ê°€ê²©: {price_elem.get_text(strip=True)[:50]}")
        
        # 7. ê³µí†µ í´ë˜ìŠ¤ëª… ë¶„ì„
        print("\n[7] ìì£¼ ì‚¬ìš©ë˜ëŠ” í´ë˜ìŠ¤ëª… (TOP 20):")
        _v_all_classes = {}
        for elem in _v_soup.find_all(class_=True):
            for cls in elem.get('class', []):
                _v_all_classes[cls] = _v_all_classes.get(cls, 0) + 1
        
        _v_sorted_classes = sorted(_v_all_classes.items(), key=lambda x: x[1], reverse=True)
        for idx, (cls, count) in enumerate(_v_sorted_classes[:20], 1):
            # í˜œíƒ/ì¿ í°/ìƒí’ˆ ê´€ë ¨ í´ë˜ìŠ¤ë§Œ ì¶œë ¥
            if any(keyword in cls.lower() for keyword in ['benefit', 'coupon', 'product', 'item', 'event', 'promotion', 'gift', 'title', 'date']):
                print(f"   {idx}. {cls}: {count}íšŒ")
        
        # 8. iframe í™•ì¸
        print("\n[8] iframe í™•ì¸:")
        _v_iframes = _v_soup.find_all('iframe')
        if _v_iframes:
            print(f"   iframe {len(_v_iframes)}ê°œ ë°œê²¬")
            for idx, iframe in enumerate(_v_iframes, 1):
                src = iframe.get('src', 'N/A')
                print(f"      [{idx}] src: {src[:100]}")
        else:
            print("   iframe ì—†ìŒ")
        
        print("\n" + "=" * 80)
        print("âœ… ë¶„ì„ ì™„ë£Œ!")
        print("=" * 80)
        print("\nğŸ“ ìƒì„±ëœ íŒŒì¼:")
        print("   - naver_shopping_page_source.html (HTML ì†ŒìŠ¤)")
        print("   - naver_shopping_screenshot.png (ìŠ¤í¬ë¦°ìƒ·)")
        
    except Exception as e:
        print(f"\nâŒ ì—ëŸ¬ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        _v_driver.quit()
        print("\nğŸ”š ë¸Œë¼ìš°ì € ì¢…ë£Œ")

if __name__ == "__main__":
    analyze_page()
